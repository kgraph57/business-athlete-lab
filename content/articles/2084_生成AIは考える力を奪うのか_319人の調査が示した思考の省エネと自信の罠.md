# 【論文紹介】生成AIは「考える力」を奪うのか？📖 319人の調査が示した“思考の省エネ”と自信の罠

**記事ID:** n171d3cd473cf
**公開日:** 2025-12-14 06:00:00
**カテゴリ:** 健康・医療
**元記事URL:** https://note.com/kgraph_/n/n171d3cd473cf

---

## 記事内容

[図表]📖 この記事は約8分で読めます## 0. スナップサマリー🔍
1️⃣ 生成AIを使うと、知識労働者は「批判的思考（critical thinking）」の実行を約60%のケースで自覚していました（=裏を返せば約40%は“あまり考えないまま”進む可能性）。2️⃣ AIへの自信が高いほど、批判的思考の実行は減る（一方、自分のスキルやAI出力を評価する自信が高いほど増える）。3️⃣ 注意点：自己申告の調査であり、「楽になった＝考えなくなった」と混同する回答も起きうる（研究者も限界として明記）。## 1. 導入（ストーリー部分）📖
40代の営業マネージャー田中さん。提案書、メール、議事録、競合調査…とにかく“考える仕事”が終わりません。そこで導入した生成AI。要点整理も文章のたたき台も秒速で返ってくる。田中さんは思いました。「これでラクになった。…でも最近、自分の頭で検証する回数が減ってない？」このモヤモヤに、真正面から切り込んだのが今回の論文です。「AIで生産性は上がる。でも“考える筋肉”はどうなる？」——ここをデータで覗いています。## 2. 研究の紹介（論文情報）📜- 論文タイトル：The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers- 邦題（意訳）：生成AIが批判的思考に与える影響：知識労働者の調査から見えた“認知的努力の低下”と“自信”の効果- 著者：Hao-Ping (Hank) Lee（第一著者）／Nicholas Wilson（最終著者）ほか計7名- 雑誌（会議）：CHI Conference on Human Factors in Computing Systems (CHI ’25)（ACM）- ページ等：23 pages- DOI／URL：[https://doi.org/10.1145/3706598.3713778](https://doi.org/10.1145/3706598.3713778)- 第一所属・国：Carnegie Mellon University（米国）／Microsoft Research（英国）- 研究タイプ：オンライン調査研究（Prolific上で実施）- 倫理・試験登録：臨床試験ではなく登録番号の対象外（本文に臨床試験登録の記載なし）- 資金・COI：本文末尾に謝辞（Microsoft Researchのグループ等）記載あり／明示的なCOI記載は本文中で確認できませんでした焦点：生成AI使用時に、知識労働者は「いつ」「どのように」批判的思考を実行していると感じるのか。さらに、生成AIがその“考える努力”を増やすのか減らすのか、何がその差を生むのか。## 3. 研究の要旨（かみ砕き版）📖## 対象- 生成AI（例：ChatGPT、Copilot）を仕事で週1回以上使う知識労働者：n=319- 具体的な“生成AIを使った仕事の実例”を集め、合計936例を分析## 何を測った？- その仕事で「批判的思考を実行したと感じたか」（True/False）- Bloomのタキソノミー（知識→理解→応用→分析→統合→評価）に沿って、各思考活動の“努力感”が、AIなしと比べて増えた／減った／同じか## 主要結果（重要ポイントだけ、数字は厳密に）- 936例のうち、批判的思考を実行したと自己申告したのは約60%（555/936）。- 「批判的思考を実行したかどうか」に関する回帰分析では：AIでそのタスクをこなせるという自信が高いほど、批判的思考の実行は低下（β=-0.69, p- 努力感（「楽になった／大変になった」）は、全体として“減る”側に傾く分布：例：評価（evaluation）では「-2/-1/0/1/2」の5段階のうち、-2と-1（努力が減った側）の合計が 177+246=423、0（同じ）が221、増えた側（1と2）が84+36=120（N=764）。## 有害事象・安全性
医療介入研究ではないため、いわゆる有害事象報告の枠組みではありません。ただし自由記述では、誤り・古い情報・数学ミス・高リスク業務での不安などが“批判的思考の動機”として多数出てきます。## 限界（著者が明記）- 「AIでラクになった」ことと「批判的思考が減った」ことを混同する回答がある（自己申告の弱点）。- 自己評価の自信は、客観的な専門性とズレる可能性がある。- 英語話者のみ、かつ若年・技術慣れ・AI頻用者に偏りうる。- 生成AIは変化が速く、結果は将来変わりうる（ベースラインとしての価値）。## 4. 研究結果の発見（対話形式）🗣️
💬 主人公：「AIが賢くなるほど、人って考えなくなるんですか？ 便利すぎて怖い…」👨‍⚕️ 専門家（研究者）：「“考えなくなる”と断定はできませんが、この調査では AIへの自信が高い人ほど、批判的思考を実行したという申告が減りました。つまり、AIを“できるやつだ”と感じるほど、チェックや吟味が薄くなる方向に倒れやすい、という傾向が見えています。」💬 主人公：「じゃあ、AIを疑って使えばいい？」👨‍⚕️ 専門家：「疑うというより、“自分の自信”を育てるのがポイントです。自分でできる自信、そしてAI出力を評価できる自信が高いほど、批判的思考が増える方向に関連していました。つまり…AIを使うほど、評価力（レビュー力）を鍛えないと危ない、という示唆です。」💬 主人公：「でもAIを使うと“ラク”になるのは事実ですよね？」👨‍⚕️ 専門家：「その通り。面白いのは“ラクになる場所”が変わることです。情報収集そのものは減る一方で、情報の検証、出力の統合、そして“成果物の責任を持つ管理（stewardship）”に思考が移ります。AIは作業を消すけど、あなたを“編集長”にします。たまにポンコツな記者も雇った状態で、です（笑）。」## 5. 実践ガイド💼（研究を“行動”に変える）
忙しいビジネスアスリート向けに、「今日からできる」形に落とします。- 🧠 1) AIの出力を“採用する前”に、評価の型を固定する例：「根拠は？」「前提は？」「反例は？」「自社文脈に合う？」の4点だけでもチェックリスト化。- 🔍 2) 重要タスクほど、外部ソースで“最低1回”クロスチェック生成AIの弱点（誤り・古い情報・断定）を前提に、出典確認を儀式にする。- 🧩 3) そのまま貼らずに“統合”する（AI response integration）AI案は「材料」。あなたの経験・数字・顧客条件と混ぜて、1枚上の提案にする。- 🧭 4) 自分の自信が低い領域ほど、AIの自信を下げる運用にする「この領域は誤りが出やすい」と決めたら、AIの回答を“仮説”扱いに格下げする。- 📝 5) 週1回だけ“振り返り”を入れる研究では、普段から仕事を振り返る傾向が強い人ほど批判的思考が増える関連がありました。3分でOK：「AIに任せた部分／自分が判断した部分」をメモするだけ。## 6. まとめ・結論🎯
生成AIは、知識労働の“考える配分”を変えます。そして厄介なのは、AIを信じるほど、人はチェックしなくなる方向に傾きうること。だからこそ、これからのビジネスアスリートに必要なのは「速く作る力」だけではなく、「評価し、統合し、責任を持つ力（＝編集長力）」です。私たちの仕事は、AIで軽くなっていく。でも“軽くなるほど大事になる筋肉”がある——それを思い出させてくれる論文でした。## 7. 参考文献📚
Hao-Ping (Hank) Lee, Advait Sarkar, Lev Tankelevitch, Ian Drosos, Sean Rintel, Richard Banks, and Nicholas Wilson. 2025.The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers.In CHI Conference on Human Factors in Computing Systems (CHI ’25). ACM, 23 pages.[https://doi.org/10.1145/3706598.3713778](https://doi.org/10.1145/3706598.3713778)## 8. 関連論文ピックアップ🔍- [Experimental evidence on the productivity effects of generative artificial intelligence](https://www.science.org/doi/10.1126/science.adh2586) — 生成AIが生産性・品質を上げる一方で、タスクの性質によって効果が変わりうる点を示す研究。- [How Knowledge Workers Use and Want to Use LLMs in an Enterprise Context](https://dl.acm.org/doi/10.1145/3613905.3650841) — 知識労働者がLLMをどう使い、今後どう使いたいかの整理に役立つ。- [To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making](https://doi.org/10.1145/3449287) — AIへの過信（overreliance）を減らすための設計介入（強制的に考えさせる仕掛け）の実験研究。## 9. 📰 あわせて読みたい（関連記事カード）
[https://note.com/kgraph_/n/n589d2eb7b68c](https://note.com/kgraph_/n/n589d2eb7b68c)[https://note.com/kgraph_/n/n25c55b6e33e1](https://note.com/kgraph_/n/n25c55b6e33e1)[https://note.com/kgraph_/n/n5ee491b3dd5f](https://note.com/kgraph_/n/n5ee491b3dd5f)## 10. ハッシュタグ🏷️
#ビジネスアスリート #健康戦略 #運動習慣 #睡眠 #栄養 #予防医療 #再現性要検証 #論文紹介 #働く身体 #健康経営[図表]

---

*文字数: 4588文字*
